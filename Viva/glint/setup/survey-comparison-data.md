---
title: Choose your benchmark comparison data for Viva Glint reporting
description: Choosing the right comparison data when setting up feedback reporting sets the right context for understanding strengths and opportunities.
ms.author: JudithWeiner
author: JudyWeiner
manager: MelissaBarry
audience: admin
f1.keywords: NOCSH
keywords: Benchmarks, global benchmark, internal benchmark, external benchmark, survey comparators, My Teams, Average Question
ms.collection: 
 - m365initiative-viva
 - selfserve
search-appverid: MET150
ms.topic: article
ms.service: viva-glint
ms.localizationpriority: high
ms.date: 12/17/2024
---

# Choose your benchmark comparison data for Viva Glint reporting

Choosing the right benchmark comparison when considering Microsoft Viva Glint survey results sets the right context for understanding strengths and opportunities and makes the difference between effective progress and misdirected actions. Good comparison choices are crucial. Managers need to find the right comparison for understanding their engagement feedback.

Comparisons come from these sources:

- **Internal:** Compared to your organization's overall scores or another internal group
- **Historical:** Compared to previous survey results
- **External:** Compared to external benchmarks, comprised of scores across Glint customers

Use a combination of comparative data to reveal the most comprehensive information for your managers.

> [!NOTE]
> Your company may use custom terms for the Viva Glint terminology used in this guidance.

## How to change the comparison in a report

The company admin chooses the default comparison for survey data. Managers can choose to view a different comparison group to provide more context for your survey scores from any report they have access to.

1. From the **Reports** tab, choose the report and then select the **Settings** button. The **Report Settings** slider window opens.
2. Under **Comparison**, use the down-facing arrow next to change the  comparator.
3. Select **Done**.

## Understand the four comparison settings

Viva Glint provides four options for comparison reporting by default. In addition to the following four settings, your company may have one or more internal comparisons configured (for example, Division or Business Unit).

|Comparator|Description|When to use|
|-------|--------|-----------|
|**Benchmark**|Provides a comparison point for feedback based on survey data compiled from all Viva Glint customers.| Helpful for admins and first-time survey results analysis|
|**Company** â€¯| Displays team scores in comparison to company-wide scores for the same questions.| Helpful for users with more than one area of responsibility|
|**My Teams** | Compares a manager's team score to an overall score derived from a filter.| This setting is the superset of access and is best used with custom access or managers with large organizations|
|**Average Question** |Presents a single, overall score for all questions and respondents within your access.| Helpful for users looking for some level of variance in their score|

## Why are comparison choices beneficial?

**Comparison scores within the platform enable you to make sense of your results.** Without meaningful comparison data, inaccurate conclusions may cause you to focus on the wrong areas for improvement.

**Algorithms built into the platform take comparative data sets into consideration**. The Glint platform intelligently highlights Strengths and Opportunities. The platform considers a combination of survey results, their impact on the outcomes you care about, and where you stand on available comparisons.

**Comparisons between groups within an organization may be helpful to score interpretation.** For groups that typically score higher relative to other groups on a set of priority questions, it may be useful to source best practices from that group. Then share them with other groups to support broad scale improvement.

## Determine which comparison data to use

Decide which comparison data can be most useful. Consider your company's overall business and measurement strategy. Consider where you are in your survey cycle - first survey, subsequent surveys, etc.

In general, external benchmarks provide useful level-setting comparisons during an initial survey, but aren't as useful to your organization as internal and trend (historical) comparisons in subsequent surveys.

### When is the external benchmark comparison useful?

For an initial survey, when no historical data exists, most organizations are interested in seeing how their scores compare to an *external* benchmark. This practice is a good way to begin orient your organization to their results. Viva Glint has more than 180 survey questions with benchmark data by industry, function, and country.

As you begin to survey more frequently, trends and internal comparisons become more useful than external benchmarks. They help you make incremental improvements in areas that matter most to your teams. While the external benchmark provides a meaningful reference point in assessing overall scores, managers shouldn't focus heavily on it. 

**For managers, the internal comparison and their own team's past survey scores are the best comparisons.**

> [!TIP]
> Use [Viva Glint's global benchmark offerings and methodology](benchmarks.md) for external benchmarking comparisons.

### When is the "Total Company" or other internal comparison useful?

Managers are best served by using an internal comparison. This is most often your organization's **Total Company** scores. Your company may have other internal comparisons set up that may be more meaningful. The internal comparison provides a more relevant comparison point for managers than the external benchmark.

After the first survey, managers should focus on their team's trend - change in scores over time - to see progress and where opportunities lie.

> [!TIP]
> For Employee Lifecycle surveys, internal comparisons highlight the uniqueness of employee experiences by organization. There are, however, external benchmarks for standard onboarding and exit items.

### When is the "My Teams" comparison useful?

The **My Teams** comparison represents the scores for the user's total access within Viva Glint. 
- For company admins, the **My Teams** comparison is the same as the **Company** comparison since they have access to all company data.
- For a manager, **My Teams** represents the scores for everyone who reports up through them (their roll-up organization).

> [!NOTE]
> If no filter is applied to a report, the *My Teams* comparison is the same as your overall scores and will show no differences. For the *My Team*s comparison to be useful, look at filtered data (for example, subteams within the hierarchy, specific attribute groups, etc.)

The **My Teams** comparison tends to be most useful for higher level managers or those who oversee large organizations.

### When is the "Average Question" comparison useful?

Use the **Average Question** comparison under these circumstances:

- For any survey when there's no available comparisons (such as trend or external benchmark)
- For any survey where the difference between your score and others is small, such as versus **Company Overall**

In these instances, the **Average Question** score allows a comparison measurement that highlights the highest and lowest scoring items. This comparison can be used as a launching point for conversation and choosing Focus Areas.

## Tips for choosing comparisons 

- **Don't rely on external benchmarks indefinitely.** For some leaders, it's critical to understand how similar organizations are scoring. This knowledge helps them decide where to prioritize actions to deliver the same or better employee experiences. Best practice: focusing on internal comparisons over external benchmarks addresses your organization's unique strengths and opportunities.
- **Learn how to interpret differences in scores.** To determine where to take action, understand the magnitude of positive or negative differences between your scores and other comparison scores.
- **Caution small team managers on using external benchmarks as comparisons.** Benchmark data represents an average of millions of data points. External benchmarks are meant to be used for assessing organization overall scores. A better comparison for first-line managers is past survey scores (trend) for their own team or organization averages.

### Keep in mind

When comparing two groups, a group against a benchmark, or a score change over time, consider both practical and statistical significance.

- **Practical significance:** The difference in the scores between two groups that is large enough to observe unique patterns. If a score difference between two teams is too small to detect any material difference, that difference may not carry as much practical significance.
- **Statistical significance:** The probability that the difference between the scores of two groups isn't chance or coincidence but accurately represents the unique responses of individuals in each group. This is useful with larger groups, where it can be used to surface reliable patterns in data. On your platform, Alerts and Driver Impact analysis automatically check for statistical significance and display significant results.


